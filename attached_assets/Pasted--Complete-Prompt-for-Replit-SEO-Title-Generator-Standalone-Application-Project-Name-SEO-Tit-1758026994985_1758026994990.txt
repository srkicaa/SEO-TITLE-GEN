● Complete Prompt for Replit - SEO Title Generator Standalone Application

  Project Name: SEO Title Generator Pro

  Description: Build a standalone Python Streamlit application that generates SEO-optimized titles for bulk orders
  by analyzing website styles and matching them with target sites. The app should learn from successful placements
  and support both GPT-5 and Claude APIs.

  Core Requirements:

  1. Application Structure:
  Create a Python Streamlit application with the following file structure:
  seo-title-generator/
  ├── app.py                 # Main Streamlit application
  ├── database.py            # SQLite database models and operations
  ├── scraper.py            # Web scraping functionality
  ├── ai_handler.py         # OpenAI/Claude API integration
  ├── patterns.py           # Pattern analysis and learning
  ├── utils.py              # Helper functions
  ├── requirements.txt      # Dependencies
  ├── config.yaml          # API keys and settings
  ├── database.db          # SQLite database (auto-created)
  └── exports/             # Folder for CSV exports

  2. Database Schema (SQLite):
  -- Sites table (learns patterns over time)
  CREATE TABLE sites (
      id INTEGER PRIMARY KEY,
      domain TEXT UNIQUE,
      style_patterns JSON,
      typical_title_length INTEGER,
      common_formats TEXT,
      acceptance_rate REAL,
      last_analyzed DATETIME
  );

  -- Orders table
  CREATE TABLE orders (
      id INTEGER PRIMARY KEY,
      batch_id TEXT,
      target_website TEXT,
      target_anchor TEXT,
      source_website TEXT,
      status TEXT, -- pending/processing/completed/accepted/rejected
      generated_titles JSON,
      selected_title TEXT,
      webmaster_accepted BOOLEAN,
      ai_model_used TEXT,
      created_at DATETIME,
      completed_at DATETIME
  );

  -- Successful_titles table (for learning)
  CREATE TABLE successful_titles (
      id INTEGER PRIMARY KEY,
      site_id INTEGER,
      title TEXT,
      anchor_text TEXT,
      character_count INTEGER,
      format_type TEXT,
      acceptance_date DATETIME,
      seo_score REAL,
      FOREIGN KEY (site_id) REFERENCES sites(id)
  );

  -- Style_patterns table
  CREATE TABLE style_patterns (
      id INTEGER PRIMARY KEY,
      domain TEXT,
      pattern_type TEXT, -- listicle/how-to/news/guide/question
      pattern_example TEXT,
      frequency INTEGER,
      success_rate REAL
  );

  3. Main Features to Implement:

  app.py - Main Streamlit Interface:

  import streamlit as st
  import pandas as pd
  from datetime import datetime
  import asyncio

  # Create tabs for different functions
  tab1, tab2, tab3, tab4 = st.tabs(["Single Generation", "Bulk Processing", "History", "Settings"])

  # Tab 1: Single Order Processing
  - Input fields: target_website, target_anchor, source_website
  - AI Model selector (GPT-5, Claude, Auto)
  - Generate button
  - Display 5-10 generated titles with:
    - Character count
    - SEO score
    - Style match percentage
    - Copy button for each title

  # Tab 2: Bulk Processing
  - CSV upload widget accepting format:
    target_website, target_anchor, source_website
  - Progress bar for batch processing
  - Real-time status updates
  - Download results button
  - Batch processing settings:
    - Titles per order (1-10)
    - AI model selection
    - Use historical data checkbox
    - Concurrent processing limit

  # Tab 3: History & Learning
  - Table showing all past orders
  - Filter by domain, date range, acceptance status
  - Success rate metrics per domain
  - Pattern analysis visualization
  - Mark titles as accepted/rejected for learning

  # Tab 4: Settings
  - API key configuration (OpenAI, Claude)
  - Default generation settings
  - Database management (export/import)
  - Clear cache option

  scraper.py - Web Scraping Module:

  import requests
  from bs4 import BeautifulSoup
  import re
  from urllib.parse import urlparse

  class WebsiteAnalyzer:
      def analyze_website_style(self, domain):
          """
          Scrape website and analyze title patterns
          Returns: dict with patterns, average length, common words
          """
          # Perform Google site: search to get titles
          # Extract patterns like:
          # - "Best X for Y"
          # - "Top N Ways to..."
          # - "How to X in 2024"
          # - "X vs Y: Complete Guide"

      def extract_title_patterns(self, titles):
          """
          Identify common patterns in titles
          Returns: list of pattern templates
          """

      def calculate_style_metrics(self, titles):
          """
          Calculate metrics like:
          - Average character count
          - Keyword positioning
          - Use of numbers
          - Emotional words frequency
          - Brand mentions
          """

  ai_handler.py - AI Integration:

  import openai
  from anthropic import Anthropic

  class AIHandler:
      def __init__(self, openai_key, claude_key):
          self.openai_client = openai.OpenAI(api_key=openai_key)
          self.claude_client = Anthropic(api_key=claude_key)

      def generate_titles(self, target_site, anchor_text, source_site,
                         style_patterns, model="gpt-4", count=5):
          """
          Generate SEO-optimized titles using specified AI model

          Prompt structure:
          1. Analyze the style patterns from {target_site}
          2. Create titles incorporating {anchor_text}
          3. Consider context from {source_site}
          4. Match these style patterns: {style_patterns}
          5. Follow SEO best practices:
             - 50-60 characters
             - Keyword near beginning
             - Emotional triggers
             - Numbers when appropriate
          """

      def score_title(self, title, anchor_text, target_style):
          """
          Score generated title on:
          - SEO optimization (0-100)
          - Style match (0-100)
          - Originality (0-100)
          - Predicted acceptance (0-100)
          """

  patterns.py - Pattern Learning System:

  class PatternLearner:
      def learn_from_success(self, domain, successful_title):
          """
          Update pattern database with successful titles
          Extract and store:
          - Title structure
          - Word choices
          - Format type
          """

      def predict_acceptance(self, domain, title):
          """
          Based on historical data, predict if webmaster will accept
          Returns: probability score 0-1
          """

      def get_best_patterns(self, domain):
          """
          Return top performing patterns for domain
          """

  4. Key Functionality Implementation:

  CSV Processing Example:
  def process_bulk_orders(csv_file):
      df = pd.read_csv(csv_file)
      results = []

      for index, row in df.iterrows():
          # Update progress
          st.progress((index + 1) / len(df))

          # Analyze target website style
          patterns = analyze_website_style(row['target_website'])

          # Generate titles
          titles = generate_titles(
              target_site=row['target_website'],
              anchor_text=row['target_anchor'],
              source_site=row['source_website'],
              patterns=patterns
          )

          # Store in database
          save_order(row, titles)

          results.append({
              'target_website': row['target_website'],
              'anchor_text': row['target_anchor'],
              'generated_titles': titles,
              'best_title': titles[0]['title'],
              'seo_score': titles[0]['score']
          })

      return pd.DataFrame(results)

  5. Example Input/Output:

  Input CSV:
  target_website,target_anchor,source_website
  https://www.lineups.com/sweepstakes-casinos/,sweepstakes casino,js13kgames.com
  https://www.forbes.com/betting/,online betting,sportsanalytics.com
  https://www.techcrunch.com/startups/,AI startup,mlnews.com

  Output CSV:
  target_website,anchor_text,title_1,title_2,title_3,seo_score,style_match
  lineups.com,sweepstakes casino,"Best Sweepstakes Casinos for Casual Gamers 2024","Top 10 Sweepstakes Casino Games
  to Play Now","Sweepstakes Casinos: Your Guide to Winning Big",92,88
  forbes.com,online betting,"Online Betting Strategies That Actually Work","Why Online Betting Is Transforming
  Sports Analytics","The Smart Investor's Guide to Online Betting Platforms",94,91

  6. Advanced Features:

  1. Style Matching Algorithm:
    - Analyze title structure (prefix, core, suffix)
    - Match punctuation patterns
    - Replicate capitalization style
    - Mirror emotional tone
  2. Learning System:
    - Track acceptance rates per domain
    - Identify successful patterns
    - Adjust generation parameters
    - A/B test different approaches
  3. SEO Optimization:
    - Keyword placement optimization
    - Character count optimization (50-60 chars)
    - Power words integration
    - Search intent matching
  4. Performance Features:
    - Concurrent API calls (with rate limiting)
    - Result caching
    - Batch processing with queue
    - Auto-save progress

  7. requirements.txt:
  streamlit==1.28.0
  pandas==2.0.3
  beautifulsoup4==4.12.2
  requests==2.31.0
  openai==1.3.0
  anthropic==0.7.0
  sqlite3
  pyyaml==6.0
  selenium==4.15.0
  webdriver-manager==4.0.1
  plotly==5.17.0

  8. Configuration (config.yaml):
  api_keys:
    openai: "your-openai-key"
    claude: "your-claude-key"

  settings:
    default_model: "gpt-4"
    titles_per_request: 5
    max_concurrent_requests: 3
    cache_duration_hours: 24

  scraping:
    user_agent: "Mozilla/5.0..."
    timeout: 10
    max_retries: 3

  9. Running Instructions:
  # Install dependencies
  pip install -r requirements.txt

  # Run the application
  streamlit run app.py

  # Application opens at http://localhost:8501

  10. Packaging as Standalone Executable (Optional):
  # Install PyInstaller
  pip install pyinstaller

  # Create executable
  pyinstaller --onefile --add-data "templates:templates" app.py

  # Executable created in dist/app.exe

  Critical Implementation Details:

  1. Error Handling: Implement try-catch for API calls, web scraping failures, and database operations
  2. Rate Limiting: Respect API rate limits for OpenAI/Claude
  3. Progress Tracking: Show real-time progress for bulk operations
  4. Data Validation: Validate URLs and check for duplicates
  5. Export Formats: Support CSV, JSON, and Excel exports
  6. Logging: Implement comprehensive logging for debugging

  Testing Requirements:

  - Test with the example: lineups.com + "sweepstakes casino" + js13kgames.com
  - Should generate titles matching lineups.com style
  - Character count should be 50-60
  - Anchor text should appear early in title

  This application should process 30 orders in under 5 minutes and learn from each successful placement to improve
  future generations.